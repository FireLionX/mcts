{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mSkipping mcts as it is not installed.\u001b[0m\n",
      "Processing /notebooks\n",
      "Collecting sortedcontainers>=1.5.9 (from mcts==0.4)\n",
      "  Downloading https://files.pythonhosted.org/packages/cb/53/fe764fc8042e13245b50c4032fb2f857bc1e502aaca83063dcdf6b94d223/sortedcontainers-2.0.4-py2.py3-none-any.whl\n",
      "Collecting logwood>=3.1.0 (from mcts==0.4)\n",
      "  Downloading https://files.pythonhosted.org/packages/1c/7c/1294695c7f53d6101adb88c98aacb8cfa27a68adf29debc129b7a51d88e5/logwood-3.1.0.tar.gz\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.5/dist-packages (from mcts==0.4) (1.14.2)\n",
      "Collecting keras>=2.1.4 (from mcts==0.4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/7d/b1dedde8af99bd82f20ed7e9697aac0597de3049b1f786aa2aac3b9bd4da/Keras-2.2.2-py2.py3-none-any.whl (299kB)\n",
      "\u001b[K    100% |################################| 307kB 6.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting xxhash>=1.0.1 (from mcts==0.4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/34/86bb696206293afc33b62aaa72443f2c8344048b72a1e67c3cfe6caca1dc/xxhash-1.2.0-cp35-cp35m-manylinux1_x86_64.whl (47kB)\n",
      "\u001b[K    100% |################################| 51kB 5.7MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting keras-applications==1.0.4 (from keras>=2.1.4->mcts==0.4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/90/8f327deaa37a71caddb59b7b4aaa9d4b3e90c0e76f8c2d1572005278ddc5/Keras_Applications-1.0.4-py2.py3-none-any.whl (43kB)\n",
      "\u001b[K    100% |################################| 51kB 13.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml (from keras>=2.1.4->mcts==0.4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/a3/1d13970c3f36777c583f136c136f804d70f500168edc1edea6daa7200769/PyYAML-3.13.tar.gz (270kB)\n",
      "\u001b[K    100% |################################| 276kB 6.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras>=2.1.4->mcts==0.4) (1.11.0)\n",
      "Collecting keras-preprocessing==1.0.2 (from keras>=2.1.4->mcts==0.4)\n",
      "  Downloading https://files.pythonhosted.org/packages/71/26/1e778ebd737032749824d5cba7dbd3b0cf9234b87ab5ec79f5f0403ca7e9/Keras_Preprocessing-1.0.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras>=2.1.4->mcts==0.4) (2.7.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras>=2.1.4->mcts==0.4) (1.0.1)\n",
      "Building wheels for collected packages: mcts, logwood, pyyaml\n",
      "  Running setup.py bdist_wheel for mcts ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-mozmr8_g/wheels/b6/62/b1/600ed0c11030d88f67fd6813772ff38d9f0a25ea8277435239\n",
      "  Running setup.py bdist_wheel for logwood ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/47/95/5b/a99a14ce8b2783c8e84d3cb149d7a52084629628964178323f\n",
      "  Running setup.py bdist_wheel for pyyaml ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ad/da/0c/74eb680767247273e2cf2723482cb9c924fe70af57c334513f\n",
      "Successfully built mcts logwood pyyaml\n",
      "Installing collected packages: sortedcontainers, logwood, keras-applications, pyyaml, keras-preprocessing, keras, xxhash, mcts\n",
      "Successfully installed keras-2.2.2 keras-applications-1.0.4 keras-preprocessing-1.0.2 logwood-3.1.0 mcts-0.4 pyyaml-3.13 sortedcontainers-2.0.4 xxhash-1.2.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/mattdeak/mcts.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Build Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcts.environments import TicTacToe, DotsAndBoxes\n",
    "\n",
    "env = DotsAndBoxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "Player 1 Score is 0\n",
      "Player 2 Score is 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.board()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Build Neural Network\n",
    "I've built some utility scripts to aid in this. All that's required for a working model is to have both a policy output and a value output. We'll use the `load_zeronet` utility to load a neural-net architecture similar to the AlphaGo Zero architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3221: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from mcts.nn.utils import load_zeronet\n",
    "\n",
    "from mcts.nn.model import Model\n",
    "keras_model = load_zeronet(env.state.shape, env.action_space, lr=0.001, residual_layers=2)\n",
    "mcts_model = Model(keras_model) # Takes a Keras/TF Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Configuring Policies\n",
    "There are a couple different types to choose from, but only a couple are required for MCTS to run.\n",
    "1. Selection - Policy that chooses an action during the selection phase of MCTS\n",
    "2. Expansion - Policy that expands a leaf node in MCTS.\n",
    "3. Update - Policy that determines how nodes are updated at the end of a MCTS.\n",
    "4. Action - Policy that chooses what action to play based on results of MCTS.\n",
    "\n",
    "Building a config file is pretty straightforward! Just use a json-like structure. You can check the supported policies by running the command below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple config dictionary is shown below. If you want to add keyword arguments, which some policies take, just use add `_kwargs` after the policy type and put the keyword arguments in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model' : mcts_model,\n",
    "    'action' : 'proportional-to-visit-count',\n",
    "    'selection' : 'puct',\n",
    "    'selection_kwargs' : {'C' : 1.14},\n",
    "    'expansion' : 'neural',\n",
    "    'update' : 'value'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the MCTS\n",
    "\n",
    "If you don't care about actually training your model, then you can build the MCTS with a config dictionary. Just specify the policy _type_ as the key and the policy object as the value.\n",
    "You can check the supported policy types by using `mcts.SUPPORTED_POLICY_TYPES`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcts.mcts import MCTS\n",
    "\n",
    "m = MCTS(env, calculation_time=3)\n",
    "m.build(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".    .    .    .    .\n",
      "                    \n",
      ".----.    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "Player 1 Score is 0\n",
      "Player 2 Score is 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m.act()\n",
    "env.board()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Building the Replay Table, Trainer, Evaluator and Terminal Callback\n",
    "However, we don't have a pretrained neural net. In order to _train_ the neural net, we'll need some extra classes.\n",
    "1. A Replay Table - This is just data storage for our training data,\n",
    "2. An Evaluator - This class lets us pit old models against new models in a tournament. This is how we determine if the model we're training is ready to take over in guiding the MCTS.\n",
    "3. A Trainer - This class handles the legwork in actually training the neural net.\n",
    "\n",
    "The trainer we'll be using is `StagedModelTrainer` - this will load game results into a replay table and, once a certain number of games have been reached, train the model and evaluate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Replay Table\n",
    "The replay table stores the training data. In order to format itself efficiently, it needs the dimensions of the state space and action space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcts.nn.replay import BasicReplay\n",
    "from keras.callbacks import TensorBoard\n",
    "replay = BasicReplay(env.state.shape, env.action_space, capacity=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save a replay table to a file in its current state by using the `save()` method. This comes in handy if you want to keep all the data your MCTS generates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.mkdir('replay')\n",
    "#os.mkdir('replay/dotsandboxes')\n",
    "replay.save('replay/dotsandboxes/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the saved model by using the `load_replay` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcts.nn.replay import load_replay\n",
    "replay2 = load_replay('replay/dotsandboxes/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Evaluator\n",
    "The evaluator is used to determine if one MCTS model is better than another. The NNEvaluator runs a tournament between two identical MCTS trees with the exception that one is using a different neural network. \n",
    "To instantiate the evaluator, we only need a config dictionary that contains some MCTS policies and our model.\n",
    "\n",
    "We'll just use the `most_visited` action policy here for demonstration. This action policy will just choose the action that has been explored the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcts.policies.action import MostVisited\n",
    "from mcts.evaluators import NNEvaluator\n",
    "\n",
    "evaluation_config = {\n",
    "    'model' : mcts_model,\n",
    "    'selection' : 'puct',\n",
    "    'expansion' : 'neural',\n",
    "    'update' : 'value',\n",
    "    'action' : 'most-visited'\n",
    "}\n",
    "    \n",
    "evaluator = NNEvaluator(env, evaluation_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually we won't have to run the evaluator manually, since the Trainer will handle that. However, if we ever __do__ want to run the evaluator manually, we can simply use the `.evaluate()` method. The NNEvaluator takes `incumbent_model` and `challenger_model`. We'll just test this briefly using the exact same model to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Challenger'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = evaluator.evaluate(mcts_model, mcts_model, games=1)\n",
    "results.winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Trainer\n",
    "The trainer is the thing that actually allows you to train a neural net with MCTS. To instantiate it, we require:\n",
    "1. The game environment\n",
    "2. The config for our mcts (including the model)\n",
    "3. A replay table\n",
    "4. An evaluator\n",
    "5. Any Keras Callbacks that we want. We'll use tensorboard here. (optional)\n",
    "6. A model directory. The staged model trainer will save our model every time it get updated. If no model directory is specified, then it just won't save the model. (optional)\n",
    "7. A replay directory. The trainer will save the replay table to this directory at the end of every \"data generation\" stage. (optional)\n",
    "\n",
    "Here, we're going to use a `StagedModelTrainer`. This trainer will go through three stages to train the neural network.\n",
    "\n",
    "The first stage is our data generation stage. In this stage, trainer will have the MCTS play against itself and record data from all the games. The data is stored in the replay table.\n",
    "\n",
    "The second stage is the training stage. In this stage, the trainer will use the data in the replay table to train the neural network.\n",
    "\n",
    "The third stage is the evaluation stage. In this stage, the trainer will evaluate the pre-training model and the post-training model. If the post-training model does better, then the model is updated and the cycle repeats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcts.nn.trainers import StagedModelTrainer\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# Make directories to save information\n",
    "#os.mkdir('models')\n",
    "#os.mkdir('models/dotsandboxes')\n",
    "\n",
    "trainer = StagedModelTrainer(env, config, replay, evaluator,  \n",
    "                             model_dir='models/dotsandboxes',\n",
    "                             replay_dir='replay/dotsandboxes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Initiate Self-Play\n",
    "You can simply use the `trainer.train()` method. Just set the number of games you want to play and it'll do the rest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[1534980394.1441956][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Starting epoch 0\u001b[0m\n",
      "\u001b[1;37m[1534980394.1510608][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Entering Generation Phase\u001b[0m\n",
      "\u001b[1;37m[1534980394.1529856][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 0\u001b[0m\n",
      "\u001b[1;37m[1534980434.2182453][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 1\u001b[0m\n",
      "\u001b[1;37m[1534980474.3330061][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Saving Replay Table to replay/dotsandboxes/replay0\u001b[0m\n",
      "\u001b[1;37m[1534980474.426401][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Entering Training Phase\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7615 - policy_head_loss: 3.9592 - value_head_loss: 1.3466 - val_loss: 2.5119 - val_policy_head_loss: 3.8714 - val_value_head_loss: 0.9351\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.6826 - policy_head_loss: 3.9348 - value_head_loss: 1.2133 - val_loss: 2.3481 - val_policy_head_loss: 3.8122 - val_value_head_loss: 0.6668\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.6577 - policy_head_loss: 3.8409 - value_head_loss: 1.2574 - val_loss: 2.2273 - val_policy_head_loss: 3.7771 - val_value_head_loss: 0.4602\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.3220 - policy_head_loss: 3.7574 - value_head_loss: 0.6695 - val_loss: 2.2063 - val_policy_head_loss: 3.7305 - val_value_head_loss: 0.4650\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.2952 - policy_head_loss: 3.6309 - value_head_loss: 0.7423 - val_loss: 2.2474 - val_policy_head_loss: 3.6859 - val_value_head_loss: 0.5916\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.1555 - policy_head_loss: 3.6929 - value_head_loss: 0.4010 - val_loss: 2.2455 - val_policy_head_loss: 3.6331 - val_value_head_loss: 0.6407\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.3637 - policy_head_loss: 3.5594 - value_head_loss: 0.9508 - val_loss: 2.2227 - val_policy_head_loss: 3.6002 - val_value_head_loss: 0.6281\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.5474 - policy_head_loss: 3.7091 - value_head_loss: 1.1686 - val_loss: 2.1908 - val_policy_head_loss: 3.5607 - val_value_head_loss: 0.6038\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.1925 - policy_head_loss: 3.5221 - value_head_loss: 0.6457 - val_loss: 2.1595 - val_policy_head_loss: 3.5235 - val_value_head_loss: 0.5782\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.0676 - policy_head_loss: 3.5158 - value_head_loss: 0.4021 - val_loss: 2.1268 - val_policy_head_loss: 3.4858 - val_value_head_loss: 0.5506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[1534980476.839971][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Entering Evaluation Phase\u001b[0m\n",
      "\u001b[1;37m[1534980554.9165542][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Challenger model wins - updating model...\u001b[0m\n",
      "\u001b[1;37m[1534980554.9599597][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Saving Model to models/dotsandboxes/model0\u001b[0m\n",
      "\u001b[1;37m[1534980555.0970201][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Starting epoch 1\u001b[0m\n",
      "\u001b[1;37m[1534980555.097556][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Entering Generation Phase\u001b[0m\n",
      "\u001b[1;37m[1534980555.0979748][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 0\u001b[0m\n",
      "\u001b[1;37m[1534980595.225479][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 1\u001b[0m\n",
      "\u001b[1;37m[1534980635.3403833][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Saving Replay Table to replay/dotsandboxes/replay1\u001b[0m\n",
      "\u001b[1;37m[1534980635.4183278][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Entering Training Phase\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.2970 - policy_head_loss: 3.4982 - value_head_loss: 0.8787 - val_loss: 2.3620 - val_policy_head_loss: 3.4540 - val_value_head_loss: 1.0527\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.3308 - policy_head_loss: 3.4822 - value_head_loss: 0.9622 - val_loss: 2.3348 - val_policy_head_loss: 3.4299 - val_value_head_loss: 1.0226\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.6749 - policy_head_loss: 3.5681 - value_head_loss: 1.5645 - val_loss: 2.3063 - val_policy_head_loss: 3.4121 - val_value_head_loss: 0.9833\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.3368 - policy_head_loss: 3.4990 - value_head_loss: 0.9575 - val_loss: 2.2637 - val_policy_head_loss: 3.3898 - val_value_head_loss: 0.9204\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.2129 - policy_head_loss: 3.3496 - value_head_loss: 0.8589 - val_loss: 2.2220 - val_policy_head_loss: 3.3713 - val_value_head_loss: 0.8556\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.2115 - policy_head_loss: 3.5507 - value_head_loss: 0.6552 - val_loss: 2.1656 - val_policy_head_loss: 3.3460 - val_value_head_loss: 0.7680\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.2922 - policy_head_loss: 3.4102 - value_head_loss: 0.9571 - val_loss: 2.1197 - val_policy_head_loss: 3.3154 - val_value_head_loss: 0.7067\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.2979 - policy_head_loss: 3.2605 - value_head_loss: 1.1181 - val_loss: 2.0728 - val_policy_head_loss: 3.2816 - val_value_head_loss: 0.6469\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.2111 - policy_head_loss: 3.4029 - value_head_loss: 0.8022 - val_loss: 2.0465 - val_policy_head_loss: 3.2568 - val_value_head_loss: 0.6189\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.1906 - policy_head_loss: 3.4539 - value_head_loss: 0.7101 - val_loss: 2.0294 - val_policy_head_loss: 3.2385 - val_value_head_loss: 0.6031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[1534980635.6362994][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Entering Evaluation Phase\u001b[0m\n",
      "\u001b[1;37m[1534980715.780857][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Challenger model wins - updating model...\u001b[0m\n",
      "\u001b[1;37m[1534980715.7909248][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Saving Model to models/dotsandboxes/model1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epochs=2, generation_steps=2, training_steps=10, evaluation_steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of version 0.4, only the StagedModelTrainer has been implemented. There are plans for more sophisticated training methods in future versions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
