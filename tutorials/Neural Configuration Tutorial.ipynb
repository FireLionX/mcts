{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling mcts-0.4:\n",
      "  Successfully uninstalled mcts-0.4\n",
      "Processing /notebooks\n",
      "Requirement already satisfied: sortedcontainers>=1.5.9 in /usr/local/lib/python3.5/dist-packages (from mcts==0.4) (2.0.4)\n",
      "Requirement already satisfied: logwood>=3.1.0 in /usr/local/lib/python3.5/dist-packages (from mcts==0.4) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.5/dist-packages (from mcts==0.4) (1.14.2)\n",
      "Requirement already satisfied: keras>=2.1.4 in /usr/local/lib/python3.5/dist-packages (from mcts==0.4) (2.2.0)\n",
      "Requirement already satisfied: xxhash>=1.0.1 in /usr/local/lib/python3.5/dist-packages (from mcts==0.4) (1.2.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from keras>=2.1.4->mcts==0.4) (3.13)\n",
      "Requirement already satisfied: keras-applications==1.0.2 in /usr/local/lib/python3.5/dist-packages (from keras>=2.1.4->mcts==0.4) (1.0.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras>=2.1.4->mcts==0.4) (1.11.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras>=2.1.4->mcts==0.4) (2.7.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras>=2.1.4->mcts==0.4) (1.0.1)\n",
      "Requirement already satisfied: keras-preprocessing==1.0.1 in /usr/local/lib/python3.5/dist-packages (from keras>=2.1.4->mcts==0.4) (1.0.1)\n",
      "Building wheels for collected packages: mcts\n",
      "  Running setup.py bdist_wheel for mcts ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-dk8hca1w/wheels/b6/62/b1/600ed0c11030d88f67fd6813772ff38d9f0a25ea8277435239\n",
      "Successfully built mcts\n",
      "Installing collected packages: mcts\n",
      "Successfully installed mcts-0.4\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall mcts -y\n",
    "!pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Build Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcts.environments import TicTacToe, DotsAndBoxes\n",
    "env = DotsAndBoxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "Player 1 Score is 0\n",
      "Player 2 Score is 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.board()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Build Neural Network\n",
    "I've built some utility scripts to aid in this. All that's required for a working model is to have both a policy output and a value output. We'll use the `load_zeronet` utility to load a neural-net architecture similar to the AlphaGo Zero architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3216: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from mcts.nn.utils import load_zeronet\n",
    "\n",
    "from mcts.nn.model import Model\n",
    "keras_model = load_zeronet(env.state.shape, env.action_space, lr=0.001, residual_layers=2)\n",
    "mcts_model = Model(keras_model) # Takes a Keras/TF Model\n",
    "\n",
    "pretrained_model = load_model('models/dotsandboxes/model4')\n",
    "mcts_model_pretrained = Model(pretrained_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Configuring Policies\n",
    "There are a couple different types to choose from, but only a couple are required for MCTS to run.\n",
    "1. Selection - Policy that chooses an action during the selection phase of MCTS\n",
    "2. Expansion - Policy that expands a leaf node in MCTS.\n",
    "3. Update - Policy that determines how nodes are updated at the end of a MCTS.\n",
    "4. Action - Policy that chooses what action to play based on results of MCTS.\n",
    "\n",
    "Building a config file is pretty straightforward! Just use a json-like structure. You can check the supported policies by running the command below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple config dictionary is shown below. If you want to add keyword arguments, which some policies take, just use add `_kwargs` after the policy type and put the keyword arguments in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model' : mcts_model,\n",
    "    'action' : 'proportional-to-visit-count',\n",
    "    'selection' : 'puct',\n",
    "    'selection_kwargs' : {'C' : 1.14},\n",
    "    'expansion' : 'neural',\n",
    "    'update' : 'value'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the MCTS\n",
    "\n",
    "If you don't care about actually training your model, then you can build the MCTS with a config dictionary. Just specify the policy _type_ as the key and the policy object as the value.\n",
    "You can check the supported policy types by using `mcts.SUPPORTED_POLICY_TYPES`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcts.mcts import MCTS\n",
    "\n",
    "m = MCTS(ttt, calculation_time=3)\n",
    "m.build(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1.,  1.],\n",
       "       [ 1., -1., -1.],\n",
       "       [-1.,  1.,  0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.act()\n",
    "ttt.board()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Building the Replay Table, Trainer, Evaluator and Terminal Callback\n",
    "However, we don't have a pretrained neural net. In order to _train_ the neural net, we'll need some extra classes.\n",
    "1. A Replay Table - This is just data storage for our training data,\n",
    "2. An Evaluator - This class lets us pit old models against new models in a tournament. This is how we determine if the model we're training is ready to take over in guiding the MCTS.\n",
    "3. A Trainer - This class handles the legwork in actually training the neural net.\n",
    "\n",
    "The trainer we'll be using is `StagedModelTrainer` - this will load game results into a replay table and, once a certain number of games have been reached, train the model and evaluate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Replay Table\n",
    "The replay table stores the training data. In order to format itself efficiently, it needs the dimensions of the state space and action space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcts.nn.replay import BasicReplay\n",
    "from keras.callbacks import TensorBoard\n",
    "replay = BasicReplay(ttt.state.shape, ttt.action_space, capacity=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save a replay table to a file in its current state by using the `save()` method. This comes in handy if you want to keep all the data your MCTS generates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay.save('replay/tictactoe/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the saved model by using the `load_replay` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcts.nn.replay import load_replay\n",
    "replay2 = load_replay('replay/tictactoe/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Evaluator\n",
    "The evaluator is used to determine if one MCTS model is better than another. The NNEvaluator specifically runs a tournament between two identical MCTS trees with the exception that one is using a different neural network. \n",
    "To instantiate the evaluator, we only need the config dictionary for the MCTS tree.\n",
    "\n",
    "We'll just use the `most_visited` action policy here for demonstration. This action policy will just choose the action that has been explored the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcts.policies.action import MostVisited\n",
    "from mcts.evaluators import NNEvaluator\n",
    "\n",
    "evaluation_config = {\n",
    "    'model' : mcts_model,\n",
    "    'selection' : 'puct',\n",
    "    'expansion' : 'neural',\n",
    "    'update' : 'value',\n",
    "    'action' : 'most-visited'\n",
    "}\n",
    "    \n",
    "evaluator = NNEvaluator(ttt, evaluation_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we ever want to run the evaluator manually (rather than let a terminal policy handle it), we can simply use the `.evaluate()` method. The NNEvaluator takes `incumbent_model` and `challenger_model`. We'll just test this briefly using the exact same model to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# results = evaluator.evaluate(mcts_model, mcts_model, games=1)\n",
    "# results.winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Trainer\n",
    "The trainer is the thing that actually allows you to train a neural net with MCTS. To instantiate it, we require:\n",
    "1. The environment\n",
    "2. The config for our mcts (including the model)\n",
    "3. The replay table\n",
    "4. The evaluator\n",
    "5. Any Keras Callbacks that we want. We'll use tensorboard here. (optional)\n",
    "6. A model directory. The staged model trainer will save our model every time it get updated. If no model directory is specified, then it just won't save the model. (optional)\n",
    "7. A replay directory. The trainer will save the replay table to this directory at the end of every \"data generation\" stage. (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the terminal policy\n",
    "from mcts.nn.trainers import StagedModelTrainer\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs/demo', histogram_freq=1, write_grads=True, batch_size=16)\n",
    "trainer = StagedModelTrainer(ttt, config, replay, evaluator, \n",
    "                             callbacks=[tensorboard], \n",
    "                             model_dir='models/tictactoe',\n",
    "                             replay_dir='replay/tictactoe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Initiate Self-Play\n",
    "You can simply use the `trainer.train()` method. Just set the number of games you want to play and it'll do the rest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[1531897477.6278813][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Starting epoch 0\u001b[0m\n",
      "\u001b[1;37m[1531897477.6289308][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Entering Generation Phase\u001b[0m\n",
      "\u001b[1;37m[1531897477.62938][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 0\u001b[0m\n",
      "\u001b[1;37m[1531897486.642571][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 1\u001b[0m\n",
      "\u001b[1;37m[1531897495.6545496][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 2\u001b[0m\n",
      "\u001b[1;37m[1531897502.6616416][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 3\u001b[0m\n",
      "\u001b[1;37m[1531897511.6705499][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 4\u001b[0m\n",
      "\u001b[1;37m[1531897520.6808057][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 5\u001b[0m\n",
      "\u001b[1;37m[1531897529.693242][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 6\u001b[0m\n",
      "\u001b[1;37m[1531897538.7048767][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 7\u001b[0m\n",
      "\u001b[1;37m[1531897545.7127075][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 8\u001b[0m\n",
      "\u001b[1;37m[1531897554.72494][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 9\u001b[0m\n",
      "\u001b[1;37m[1531897561.7326062][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Saving Replay Table to replay/tictactoe/0\u001b[0m\n",
      "\u001b[1;37m[1531897561.7521565][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Entering Training Phase\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4154 - policy_head_loss: 2.3138 - value_head_loss: 0.3063 - val_loss: 1.5408 - val_policy_head_loss: 2.4064 - val_value_head_loss: 0.4645\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.5725 - policy_head_loss: 2.7007 - value_head_loss: 0.2335 - val_loss: 1.5249 - val_policy_head_loss: 2.3650 - val_value_head_loss: 0.4742\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.5450 - policy_head_loss: 2.3323 - value_head_loss: 0.5469 - val_loss: 1.4875 - val_policy_head_loss: 2.2764 - val_value_head_loss: 0.4879\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.3234 - policy_head_loss: 2.2157 - value_head_loss: 0.2203 - val_loss: 1.4729 - val_policy_head_loss: 2.2309 - val_value_head_loss: 0.5041\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3105 - policy_head_loss: 2.1838 - value_head_loss: 0.2264 - val_loss: 1.4472 - val_policy_head_loss: 2.1609 - val_value_head_loss: 0.5229\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.2215 - policy_head_loss: 2.0988 - value_head_loss: 0.1335 - val_loss: 1.4538 - val_policy_head_loss: 2.1098 - val_value_head_loss: 0.5870\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.2758 - policy_head_loss: 2.0742 - value_head_loss: 0.2667 - val_loss: 1.3868 - val_policy_head_loss: 2.0756 - val_value_head_loss: 0.4874\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3979 - policy_head_loss: 2.0356 - value_head_loss: 0.5496 - val_loss: 1.3445 - val_policy_head_loss: 2.0283 - val_value_head_loss: 0.4500\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.2837 - policy_head_loss: 1.9380 - value_head_loss: 0.4187 - val_loss: 1.2991 - val_policy_head_loss: 1.9733 - val_value_head_loss: 0.4141\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2371 - policy_head_loss: 1.9102 - value_head_loss: 0.3533 - val_loss: 1.2615 - val_policy_head_loss: 1.9388 - val_value_head_loss: 0.3736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[1531897587.432838][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Entering Evaluation Phase\u001b[0m\n",
      "\u001b[1;37m[1531897603.4395761][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Challenger model wins - updating model...\u001b[0m\n",
      "\u001b[1;37m[1531897604.0004056][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Saving Model to models/tictactoe/model0\u001b[0m\n",
      "\u001b[1;37m[1531897605.7654622][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Starting epoch 1\u001b[0m\n",
      "\u001b[1;37m[1531897605.7660315][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Entering Generation Phase\u001b[0m\n",
      "\u001b[1;37m[1531897605.7664115][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 0\u001b[0m\n",
      "\u001b[1;37m[1531897612.774538][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 1\u001b[0m\n",
      "\u001b[1;37m[1531897619.7815573][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 2\u001b[0m\n",
      "\u001b[1;37m[1531897628.7892785][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 3\u001b[0m\n",
      "\u001b[1;37m[1531897637.7991214][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 4\u001b[0m\n",
      "\u001b[1;37m[1531897644.807824][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 5\u001b[0m\n",
      "\u001b[1;37m[1531897653.816795][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 6\u001b[0m\n",
      "\u001b[1;37m[1531897662.8280795][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 7\u001b[0m\n",
      "\u001b[1;37m[1531897671.8352091][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 8\u001b[0m\n",
      "\u001b[1;37m[1531897680.8486452][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Playing Generation Game 9\u001b[0m\n",
      "\u001b[1;37m[1531897687.85789][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Saving Replay Table to replay/tictactoe/1\u001b[0m\n",
      "\u001b[1;37m[1531897687.8774297][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Entering Training Phase\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.2524 - policy_head_loss: 1.9722 - value_head_loss: 0.3220 - val_loss: 1.1095 - val_policy_head_loss: 1.8759 - val_value_head_loss: 0.1324\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3035 - policy_head_loss: 1.8583 - value_head_loss: 0.5381 - val_loss: 1.0752 - val_policy_head_loss: 1.8058 - val_value_head_loss: 0.1340\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2014 - policy_head_loss: 1.9545 - value_head_loss: 0.2376 - val_loss: 1.0520 - val_policy_head_loss: 1.7117 - val_value_head_loss: 0.1816\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2735 - policy_head_loss: 2.1591 - value_head_loss: 0.1772 - val_loss: 1.0280 - val_policy_head_loss: 1.6426 - val_value_head_loss: 0.2026\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.1422 - policy_head_loss: 1.7146 - value_head_loss: 0.3591 - val_loss: 0.9763 - val_policy_head_loss: 1.5875 - val_value_head_loss: 0.1543\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.2697 - policy_head_loss: 2.0131 - value_head_loss: 0.3155 - val_loss: 0.9433 - val_policy_head_loss: 1.5390 - val_value_head_loss: 0.1370\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.2378 - policy_head_loss: 2.0015 - value_head_loss: 0.2633 - val_loss: 0.9236 - val_policy_head_loss: 1.5072 - val_value_head_loss: 0.1293\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.1210 - policy_head_loss: 1.8161 - value_head_loss: 0.2153 - val_loss: 0.9060 - val_policy_head_loss: 1.4923 - val_value_head_loss: 0.1090\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0683 - policy_head_loss: 1.7590 - value_head_loss: 0.1670 - val_loss: 0.8851 - val_policy_head_loss: 1.4860 - val_value_head_loss: 0.0735\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.0086 - policy_head_loss: 1.7210 - value_head_loss: 0.0855 - val_loss: 0.8782 - val_policy_head_loss: 1.4880 - val_value_head_loss: 0.0578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[1531897695.9104323][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Entering Evaluation Phase\u001b[0m\n",
      "\u001b[1;37m[1531897713.9195662][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Challenger model wins - updating model...\u001b[0m\n",
      "\u001b[1;37m[1531897713.9322832][localhost][/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py][StagedModelTrainer][INFO] Saving Model to models/tictactoe/model1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epochs=2, generation_steps=10, training_steps=10, evaluation_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_model = load_model('models/dotsandboxes/model4')\n",
    "good_mcts_model = Model(good_model)\n",
    "keras_model = load_zeronet(env.state.shape, env.action_space, lr=0.001, residual_layers=4)\n",
    "random_model = Model(keras_model) # Takes a Keras/TF Model\n",
    "\n",
    "good_config = {\n",
    "    'model' : good_mcts_model,\n",
    "    'selection' : 'puct',\n",
    "    'expansion' : 'neural',\n",
    "    'update' : 'value',\n",
    "    'action' : 'most-visited'\n",
    "}\n",
    "\n",
    "bad_config = {\n",
    "    'model' : random_model,\n",
    "    'selection' : 'puct',\n",
    "    'expansion' : 'neural',\n",
    "    'update' : 'value',\n",
    "    'action' : 'most-visited'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcts.mcts import MCTS\n",
    "good_player = MCTS(env, calculation_time=1)\n",
    "bad_player = MCTS(env, calculation_time=1)\n",
    "\n",
    "good_player.build(good_config)\n",
    "bad_player.build(bad_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = {\n",
    "    1: bad_player,\n",
    "    2: good_player\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "Player 1 Score is 0\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: 0.016941165551543236\n",
      ".----.    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "Player 1 Score is 0\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: -0.2530079483985901\n",
      ".----.    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "                    |    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "Player 1 Score is 0\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: 0.04569195955991745\n",
      ".----.    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .----.    .    .\n",
      "                    |    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "Player 1 Score is 0\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: -0.011231295764446259\n",
      ".----.    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "               |    \n",
      ".    .----.    .    .\n",
      "                    |    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "Player 1 Score is 0\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: 0.04755125567317009\n",
      ".----.    .    .----.\n",
      "                    \n",
      ".    .    .    .    .\n",
      "               |    \n",
      ".    .----.    .    .\n",
      "                    |    \n",
      ".    .    .    .    .\n",
      "                    \n",
      ".    .    .    .    .\n",
      "Player 1 Score is 0\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: 0.17472580075263977\n",
      ".----.    .    .----.\n",
      "                    \n",
      ".    .    .    .    .\n",
      "               |    \n",
      ".    .----.    .    .\n",
      "                    |    \n",
      ".    .    .    .    .\n",
      "          |         \n",
      ".    .    .    .    .\n",
      "Player 1 Score is 0\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: 0.047531407326459885\n",
      ".----.    .    .----.\n",
      "                    \n",
      ".    .    .    .----.\n",
      "               |    \n",
      ".    .----.    .    .\n",
      "                    |    \n",
      ".    .    .    .    .\n",
      "          |         \n",
      ".    .    .    .    .\n",
      "Player 1 Score is 0\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: 0.21527059376239777\n",
      ".----.    .    .----.\n",
      "                    \n",
      ".    .    .    .----.\n",
      "          |    |    \n",
      ".    .----.    .    .\n",
      "                    |    \n",
      ".    .    .    .    .\n",
      "          |         \n",
      ".    .    .    .    .\n",
      "Player 1 Score is 0\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: 0.032793980091810226\n",
      ".----.    .    .----.\n",
      "                    \n",
      ".    .    .    .----.\n",
      "          |    |    \n",
      ".    .----.    .    .\n",
      "                    |    \n",
      ".    .    .    .    .\n",
      "          |         \n",
      ".    .____.    .    .\n",
      "Player 1 Score is 0\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: -0.04399741813540459\n",
      ".----.    .    .----.\n",
      "                    \n",
      ".    .    .    .----.\n",
      "          |    |    \n",
      ".    .----.----.    .\n",
      "                    |    \n",
      ".    .    .    .    .\n",
      "          |         \n",
      ".    .____.    .    .\n",
      "Player 1 Score is 0\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: 0.04206874966621399\n",
      ".----.    .----.----.\n",
      "                    \n",
      ".    .    .    .----.\n",
      "          |    |    \n",
      ".    .----.----.    .\n",
      "                    |    \n",
      ".    .    .    .    .\n",
      "          |         \n",
      ".    .____.    .    .\n",
      "Player 1 Score is 0\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: 0.04803144186735153\n",
      ".----.    .----.----.\n",
      "                    |    \n",
      ".    .    .    .----.\n",
      "          |    |    \n",
      ".    .----.----.    .\n",
      "                    |    \n",
      ".    .    .    .    .\n",
      "          |         \n",
      ".    .____.    .    .\n",
      "Player 1 Score is 0\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: 0.042090751230716705\n",
      ".----.    .----.----.\n",
      "                    |    \n",
      ".    .    .----.----.\n",
      "          |    |    \n",
      ".    .----.----.    .\n",
      "                    |    \n",
      ".    .    .    .    .\n",
      "          |         \n",
      ".    .____.    .    .\n",
      "Player 1 Score is 1\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: 0.04661727696657181\n",
      ".----.    .----.----.\n",
      "                    |    \n",
      ".    .    .----.----.\n",
      "          |    |    \n",
      ".    .----.----.    .\n",
      "                    |    \n",
      ".    .    .    .    .\n",
      "          |         \n",
      ".____.____.    .    .\n",
      "Player 1 Score is 1\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: 0.01563328318297863\n",
      ".----.    .----.----.\n",
      "                    |    \n",
      ".    .    .----.----.\n",
      "          |    |    \n",
      ".    .----.----.    .\n",
      "                    |    \n",
      ".    .    .    .    .\n",
      "          |         \n",
      ".____.____.    .____.\n",
      "Player 1 Score is 1\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: 0.03517322614789009\n",
      ".----.    .----.----.\n",
      "                    |    \n",
      ".    .    .----.----.\n",
      "          |    |    \n",
      ".    .----.----.----.\n",
      "                    |    \n",
      ".    .    .    .    .\n",
      "          |         \n",
      ".____.____.    .____.\n",
      "Player 1 Score is 1\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: -0.00618576118722558\n",
      ".----.    .----.----.\n",
      "                    |    \n",
      ".    .    .----.----.\n",
      "          |    |    \n",
      ".    .----.----.----.\n",
      "                    |    \n",
      ".    .----.    .    .\n",
      "          |         \n",
      ".____.____.    .____.\n",
      "Player 1 Score is 1\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: 0.02955741435289383\n",
      ".----.    .----.----.\n",
      "                    |    \n",
      ".    .    .----.----.\n",
      "          |    |    \n",
      ".    .----.----.----.\n",
      "                    |    \n",
      ".    .----.    .    .\n",
      "     |    |         \n",
      ".____.____.    .____.\n",
      "Player 1 Score is 2\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: 0.04877813160419464\n",
      ".----.    .----.----.\n",
      "                    |    \n",
      ".    .    .----.----.\n",
      "          |    |    \n",
      ".    .----.----.----.\n",
      "                    |    \n",
      ".----.----.    .    .\n",
      "     |    |         \n",
      ".____.____.    .____.\n",
      "Player 1 Score is 2\n",
      "Player 2 Score is 0\n",
      "\n",
      "Value: 0.04043492674827576\n",
      ".----.    .----.----.\n",
      "                    |    \n",
      ".    .    .----.----.\n",
      "          |    |    \n",
      ".    .----.----.----.\n",
      "                    |    \n",
      ".----.----.    .    .\n",
      "|    |    |         \n",
      ".____.____.    .____.\n",
      "Player 1 Score is 2\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: 0.06767984479665756\n",
      ".----.    .----.----.\n",
      "|                   |    \n",
      ".    .    .----.----.\n",
      "          |    |    \n",
      ".    .----.----.----.\n",
      "                    |    \n",
      ".----.----.    .    .\n",
      "|    |    |         \n",
      ".____.____.    .____.\n",
      "Player 1 Score is 2\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: 0.06320999562740326\n",
      ".----.    .----.----.\n",
      "|    |              |    \n",
      ".    .    .----.----.\n",
      "          |    |    \n",
      ".    .----.----.----.\n",
      "                    |    \n",
      ".----.----.    .    .\n",
      "|    |    |         \n",
      ".____.____.    .____.\n",
      "Player 1 Score is 2\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: 0.05327107384800911\n",
      ".----.    .----.----.\n",
      "|    |              |    \n",
      ".    .    .----.----.\n",
      "          |    |    \n",
      ".----.----.----.----.\n",
      "                    |    \n",
      ".----.----.    .    .\n",
      "|    |    |         \n",
      ".____.____.    .____.\n",
      "Player 1 Score is 2\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: 0.06978309899568558\n",
      ".----.    .----.----.\n",
      "|    |              |    \n",
      ".    .    .----.----.\n",
      "          |    |    \n",
      ".----.----.----.----.\n",
      "                    |    \n",
      ".----.----.    .    .\n",
      "|    |    |    |    \n",
      ".____.____.    .____.\n",
      "Player 1 Score is 2\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: 0.14809519052505493\n",
      ".----.    .----.----.\n",
      "|    |              |    \n",
      ".    .    .----.----.\n",
      "|         |    |    \n",
      ".----.----.----.----.\n",
      "                    |    \n",
      ".----.----.    .    .\n",
      "|    |    |    |    \n",
      ".____.____.    .____.\n",
      "Player 1 Score is 2\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: 0.06202131137251854\n",
      ".----.    .----.----.\n",
      "|    |         |    |    \n",
      ".    .    .----.----.\n",
      "|         |    |    \n",
      ".----.----.----.----.\n",
      "                    |    \n",
      ".----.----.    .    .\n",
      "|    |    |    |    \n",
      ".____.____.    .____.\n",
      "Player 1 Score is 3\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: 0.06653466075658798\n",
      ".----.    .----.----.\n",
      "|    |         |    |    \n",
      ".    .    .----.----.\n",
      "|         |    |    \n",
      ".----.----.----.----.\n",
      "                    |    \n",
      ".----.----.    .    .\n",
      "|    |    |    |    |    \n",
      ".____.____.    .____.\n",
      "Player 1 Score is 3\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: 0.20040777325630188\n",
      ".----.    .----.----.\n",
      "|    |         |    |    \n",
      ".    .    .----.----.\n",
      "|         |    |    \n",
      ".----.----.----.----.\n",
      "                    |    \n",
      ".----.----.    .    .\n",
      "|    |    |    |    |    \n",
      ".____.____.____.____.\n",
      "Player 1 Score is 3\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: 0.06796621531248093\n",
      ".----.    .----.----.\n",
      "|    |         |    |    \n",
      ".    .    .----.----.\n",
      "|         |    |    \n",
      ".----.----.----.----.\n",
      "                    |    \n",
      ".----.----.    .----.\n",
      "|    |    |    |    |    \n",
      ".____.____.____.____.\n",
      "Player 1 Score is 4\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: 0.04924457147717476\n",
      ".----.    .----.----.\n",
      "|    |         |    |    \n",
      ".    .    .----.----.\n",
      "|         |    |    \n",
      ".----.----.----.----.\n",
      "|                   |    \n",
      ".----.----.    .----.\n",
      "|    |    |    |    |    \n",
      ".____.____.____.____.\n",
      "Player 1 Score is 4\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: 0.29932475090026855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".----.    .----.----.\n",
      "|    |         |    |    \n",
      ".    .    .----.----.\n",
      "|    |    |    |    \n",
      ".----.----.----.----.\n",
      "|                   |    \n",
      ".----.----.    .----.\n",
      "|    |    |    |    |    \n",
      ".____.____.____.____.\n",
      "Player 1 Score is 4\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: 0.03987700864672661\n",
      ".----.    .----.----.\n",
      "|    |         |    |    \n",
      ".    .    .----.----.\n",
      "|    |    |    |    \n",
      ".----.----.----.----.\n",
      "|    |              |    \n",
      ".----.----.    .----.\n",
      "|    |    |    |    |    \n",
      ".____.____.____.____.\n",
      "Player 1 Score is 5\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: 0.021535372361540794\n",
      ".----.    .----.----.\n",
      "|    |         |    |    \n",
      ".    .----.----.----.\n",
      "|    |    |    |    \n",
      ".----.----.----.----.\n",
      "|    |              |    \n",
      ".----.----.    .----.\n",
      "|    |    |    |    |    \n",
      ".____.____.____.____.\n",
      "Player 1 Score is 6\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: 0.018151627853512764\n",
      ".----.    .----.----.\n",
      "|    |         |    |    \n",
      ".    .----.----.----.\n",
      "|    |    |    |    |    \n",
      ".----.----.----.----.\n",
      "|    |              |    \n",
      ".----.----.    .----.\n",
      "|    |    |    |    |    \n",
      ".____.____.____.____.\n",
      "Player 1 Score is 7\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: 0.020082728937268257\n",
      ".----.    .----.----.\n",
      "|    |    |    |    |    \n",
      ".    .----.----.----.\n",
      "|    |    |    |    |    \n",
      ".----.----.----.----.\n",
      "|    |              |    \n",
      ".----.----.    .----.\n",
      "|    |    |    |    |    \n",
      ".____.____.____.____.\n",
      "Player 1 Score is 8\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: 0.007033445872366428\n",
      ".----.----.----.----.\n",
      "|    |    |    |    |    \n",
      ".    .----.----.----.\n",
      "|    |    |    |    |    \n",
      ".----.----.----.----.\n",
      "|    |              |    \n",
      ".----.----.    .----.\n",
      "|    |    |    |    |    \n",
      ".____.____.____.____.\n",
      "Player 1 Score is 9\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: -0.005418240092694759\n",
      ".----.----.----.----.\n",
      "|    |    |    |    |    \n",
      ".    .----.----.----.\n",
      "|    |    |    |    |    \n",
      ".----.----.----.----.\n",
      "|    |    |         |    \n",
      ".----.----.    .----.\n",
      "|    |    |    |    |    \n",
      ".____.____.____.____.\n",
      "Player 1 Score is 10\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: -0.00661100447177887\n",
      ".----.----.----.----.\n",
      "|    |    |    |    |    \n",
      ".    .----.----.----.\n",
      "|    |    |    |    |    \n",
      ".----.----.----.----.\n",
      "|    |    |    |    |    \n",
      ".----.----.    .----.\n",
      "|    |    |    |    |    \n",
      ".____.____.____.____.\n",
      "Player 1 Score is 11\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: 0.02145010605454445\n",
      ".----.----.----.----.\n",
      "|    |    |    |    |    \n",
      ".    .----.----.----.\n",
      "|    |    |    |    |    \n",
      ".----.----.----.----.\n",
      "|    |    |    |    |    \n",
      ".----.----.----.----.\n",
      "|    |    |    |    |    \n",
      ".____.____.____.____.\n",
      "Player 1 Score is 13\n",
      "Player 2 Score is 1\n",
      "\n",
      "Value: 0.018689224496483803\n",
      ".----.----.----.----.\n",
      "|    |    |    |    |    \n",
      ".----.----.----.----.\n",
      "|    |    |    |    |    \n",
      ".----.----.----.----.\n",
      "|    |    |    |    |    \n",
      ".----.----.----.----.\n",
      "|    |    |    |    |    \n",
      ".____.____.____.____.\n",
      "Player 1 Score is 15\n",
      "Player 2 Score is 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "env.board()\n",
    "while not env.terminal:\n",
    "    m = players[env.player]\n",
    "    node = m.tree.get_by_state(env.state)\n",
    "    v = m.expand.model.predict_from_node(node)[1]\n",
    "\n",
    "    print(\"Value: {}\".format(v[0][0]))\n",
    "    players[env.player].act()\n",
    "    env.board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.player"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
